import pandas as pd
import numpy as np
import spacy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import re
import logging
import os
from collections import Counter
import pickle
from datetime import datetime

logger = logging.getLogger(__name__)

class RecommendationModel:
    def __init__(self, data_path='models/data/'):
        self.data_path = data_path
        self.nlp = None
        self.embedder = None
        self.configs = None
        self.prix_df = None
        self.config_embeddings = None
        self.scaler = StandardScaler()
        self.pca = None
        self.is_initialized = False
        
        # Enhanced synonym mapping (from your working Colab version)
        self.SYNONYMS = {
            # Budget - French to English
            'faible': 'low', 'bas': 'low', 'petit': 'low', 'Ã©conomique': 'low', 
            'pas cher': 'low', 'budget serrÃ©': 'low', 'limitÃ©': 'low',
            'moyen': 'medium', 'standard': 'medium', 'normal': 'medium', 'correct': 'medium',
            'Ã©levÃ©': 'high', 'fort': 'high', 'grand': 'high', 'cher': 'high', 
            'premium': 'high', 'luxe': 'high', 'haut de gamme': 'high',
            
            # Location - Enhanced
            'extÃ©rieur': 'extÃ©rieur', 'ext': 'extÃ©rieur', 'dehors': 'extÃ©rieur', 
            'plein air': 'extÃ©rieur', 'outdoor': 'extÃ©rieur', 'nature': 'extÃ©rieur',
            'intÃ©rieur': 'intÃ©rieur', 'int': 'intÃ©rieur', 'dedans': 'intÃ©rieur', 
            'indoor': 'intÃ©rieur', 'maison': 'intÃ©rieur',
            'studio': 'studio', 'atelier': 'studio', 'salle': 'studio',
            
            # Project Types - Enhanced
            'publicitÃ©': 'pub', 'pub': 'pub', 'commercial': 'pub', 'marketing': 'pub',
            'entretien': 'interview', 'interview': 'interview', 'reportage': 'interview',
            'docu': 'documentaire', 'documentaire': 'documentaire', 'reportage': 'documentaire',
            'court': 'court-mÃ©trage', 'mÃ©trage': 'court-mÃ©trage', 'court-mÃ©trage': 'court-mÃ©trage',
            'film': 'court-mÃ©trage', 'cinÃ©ma': 'court-mÃ©trage',
            'clip': 'clip', 'musical': 'clip', 'musique': 'clip', 'vidÃ©o musicale': 'clip',
            
            # Equipment terms
            'camera': 'camÃ©ra', 'appareil': 'camÃ©ra', 'boitier': 'camÃ©ra',
            'objectif': 'objectif', 'lens': 'objectif', 'optique': 'objectif',
            'lumiÃ¨re': 'lumiÃ¨res', 'Ã©clairage': 'lumiÃ¨res', 'flash': 'lumiÃ¨res',
            'son': 'audio', 'micro': 'audio', 'microphone': 'audio'
        }
        
        # Enhanced valid keywords (from your working model)
        self.MOTS_CLES_VALIDES = [
            'film', 'tournage', 'clip', 'pub', 'interview', 'court', 'mÃ©trage',
            'documentaire', 'budget', 'prix', 'studio', 'extÃ©rieur', 'intÃ©rieur',
            'camÃ©ra', 'lumiÃ¨re', 'objectif', 'jour', 'location', 'vidÃ©o', 'son',
            'Ã©quipement', 'matÃ©riel', 'projecteur', 'micro', 'Ã©clairage',
            'mariage', 'wedding', 'photo', 'photography', 'commercial', 'event',
            'corporate', 'nature', 'portrait', 'fashion', 'sport', 'live'
        ]

    def initialize(self):
        """Initialize the enhanced recommendation model"""
        try:
            logger.info("ðŸ¤– Initializing Enhanced Recommendation Model...")
            
            # Load NLP models
            self._load_nlp_models()
            
            # Load and process data
            self._load_enhanced_data()
            
            # Pre-compute enhanced embeddings
            self._precompute_enhanced_embeddings()
            
            # Setup advanced features
            self._setup_advanced_features()
            
            self.is_initialized = True
            logger.info("  Enhanced recommendation model initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"  Error initializing enhanced recommendation model: {e}")
            return False
    
    def _load_nlp_models(self):
        """Load and configure NLP models"""
        try:
            # Load French NLP model
            try:
                self.nlp = spacy.load('fr_core_news_sm')
                logger.info("  French NLP model loaded")
            except OSError:
                logger.warning("   French model not found. Using basic processing")
                self.nlp = None
            
            # Load the best multilingual embedding model
            self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            # Configure for better French understanding
            self.embedder.max_seq_length = 512
            logger.info("Enhanced embedding model loaded")
            
        except Exception as e:
            logger.error(f"Error loading NLP models: {e}")
            raise
    
    def _load_enhanced_data(self):
        """Load and enhance the configuration data"""
        try:
            # Load real data files
            configs_path = os.path.join(self.data_path, 'base_connaissances1.csv')
            prix_path = os.path.join(self.data_path, 'prix_materiels_final.csv')
            
            if os.path.exists(configs_path) and os.path.exists(prix_path):
                self.configs = pd.read_csv(configs_path)
                self.prix_df = pd.read_csv(prix_path)
                logger.info(f"Loaded real data: {len(self.configs)} configs, {len(self.prix_df)} prices")
            else:
                # Create enhanced sample data that matches your Colab structure
                self._create_enhanced_sample_data()
                logger.info("  Created enhanced sample data")
            
            # Clean and enhance the data
            self._clean_and_enhance_data()
            
        except Exception as e:
            logger.error(f"  Error loading enhanced data: {e}")
            raise
    
    def _create_enhanced_sample_data(self):
        """Create enhanced sample data matching your Colab version"""
        # More realistic and diverse equipment configurations
        types = ['court-mÃ©trage', 'interview', 'pub', 'documentaire', 'clip'] * 200
        budgets = ['low', 'medium', 'high'] * 334  # More balanced distribution
        lieux = ['intÃ©rieur', 'studio', 'extÃ©rieur'] * 334
        
        # Professional equipment lists (matching your real data structure)
        cameras = [
            'Sony A6400', 'Canon R6', 'Sony FX6', 'Canon C70', 'Sony A7III',
            'Canon EOS R', 'Sony A7R IV', 'Blackmagic URSA Mini Pro', 'Canon C300',
            'Sony FS7', 'Panasonic GH5', 'Canon 5D Mark IV', 'Sony A7S III'
        ] * 77
        
        objectifs = [
            'Canon 50mm f/1.8', 'Sigma 24-70mm f/2.8', 'Canon L 24-70mm f/2.8',
            'Sony FE 85mm f/1.4', 'Sigma 18-35mm f/1.8', 'Canon 85mm f/1.2',
            'Sony FE 24-70mm f/2.8', 'Sigma 35mm f/1.4', 'Canon 16-35mm f/2.8'
        ] * 112
        
        lumieres = [
            'Neewer LED Panel', 'Aputure Amaran 100x', 'Aputure 300x', 
            'Godox SL-60W', 'Aputure Amaran 200x', 'Litepanels Gemini 2x1',
            'Arri Signature Prime 35mm', 'Creamsource Vortex8'
        ] * 125
        
        # Generate realistic price estimates based on equipment quality
        prix_estimates = []
        for i in range(1000):
            budget = budgets[i]
            if budget == 'low':
                prix_estimates.append(np.random.randint(150, 400))
            elif budget == 'medium':
                prix_estimates.append(np.random.randint(350, 700))
            else:  # high
                prix_estimates.append(np.random.randint(600, 1200))
        
        self.configs = pd.DataFrame({
            'type': types,
            'budget': budgets,
            'lieu': lieux,
            'camera': cameras,
            'objectif': objectifs,
            'lumieres': lumieres,
            'prix_estime': prix_estimates
        })

        # Enhanced price data
        equipment_types = ['camera', 'objectif', 'lumieres']
        materiels = cameras[:20] + objectifs[:20] + lumieres[:15]
        types_expanded = (['camera'] * 20 + ['objectif'] * 20 + ['lumieres'] * 15)
        prix_par_jour = ([200, 250, 450, 180, 220] * 4 + [50, 80, 120, 60, 90] * 4 + [40, 60, 100, 70, 110] * 3)

        self.prix_df = pd.DataFrame({
            'type': types_expanded,
            'materiel': materiels,
            'prix_location_par_jour': prix_par_jour
        })
    
    def _clean_and_enhance_data(self):
        """Clean and enhance the loaded data"""
        # Remove any invalid entries
        self.configs = self.configs.dropna()
        self.prix_df = self.prix_df.dropna()
        
        # Standardize text fields
        self.configs['type'] = self.configs['type'].str.lower().str.strip()
        self.configs['budget'] = self.configs['budget'].str.lower().str.strip()
        self.configs['lieu'] = self.configs['lieu'].str.lower().str.strip()
        
        # Create price dictionary for fast lookup
        self.prix_dict = {}
        for _, row in self.prix_df.iterrows():
            key = (row['type'], row['materiel'])
            self.prix_dict[key] = row['prix_location_par_jour']
        
        # Calculate enhanced pricing
        self.configs['prix_jour'] = self.configs.apply(self._calculate_enhanced_prix, axis=1)
        
        # Add enhanced features
        self._add_enhanced_features()
        
        logger.info(f"  Data cleaned and enhanced: {len(self.configs)} configurations ready")
    
    def _calculate_enhanced_prix(self, config):
        """Enhanced price calculation with fallbacks"""
        try:
            camera_price = self.prix_dict.get(('camera', config['camera']), 0)
            objectif_price = self.prix_dict.get(('objectif', config['objectif']), 0)
            lumieres_price = self.prix_dict.get(('lumieres', config['lumieres']), 0)
            
            total = camera_price + objectif_price + lumieres_price
            
            # Enhanced fallback pricing logic
            if total == 0:
                base_price = config.get('prix_estime', 300)
                # Apply budget modifiers
                if config['budget'] == 'low':
                    return int(base_price * 0.7)
                elif config['budget'] == 'high':
                    return int(base_price * 1.4)
                else:
                    return int(base_price)
            
            return total
            
        except Exception:
            return config.get('prix_estime', 300)
    
    def _add_enhanced_features(self):
        """Add enhanced features for better matching"""
        # Equipment complexity score
        self.configs['complexity_score'] = self.configs.apply(self._calculate_complexity, axis=1)
        
        # Project difficulty score
        difficulty_map = {
            'interview': 2, 'pub': 4, 'documentaire': 3, 
            'court-mÃ©trage': 4, 'clip': 5
        }
        self.configs['difficulty_score'] = self.configs['type'].map(difficulty_map).fillna(3)
        
        # Location factor
        location_factor = {
            'studio': 1.0, 'intÃ©rieur': 1.2, 'extÃ©rieur': 1.5
        }
        self.configs['location_factor'] = self.configs['lieu'].map(location_factor).fillna(1.2)
        
        # Budget tier
        budget_tier = {'low': 1, 'medium': 2, 'high': 3}
        self.configs['budget_tier'] = self.configs['budget'].map(budget_tier).fillna(2)
    
    def _calculate_complexity(self, row):
        """Calculate equipment complexity score"""
        score = 1
        
        # Camera complexity
        if 'FX6' in row['camera'] or 'C70' in row['camera']:
            score += 2
        elif 'R6' in row['camera'] or 'A7III' in row['camera']:
            score += 1
        
        # Lens complexity
        if 'L' in row['objectif'] or '2.8' in row['objectif']:
            score += 1
        
        # Light complexity
        if 'Aputure' in row['lumieres'] or 'Arri' in row['lumieres']:
            score += 1
        
        return score
    
    def _precompute_enhanced_embeddings(self):
        """Pre-compute enhanced embeddings with better text representation"""
        try:
            config_texts = []
            
            for _, row in self.configs.iterrows():
                # Create rich text representations
                text_parts = [
                    row['type'],
                    row['budget'] + ' budget',
                    row['lieu'] + ' location',
                    'camera ' + row['camera'],
                    'lens ' + row['objectif'],
                    'lights ' + row['lumieres']
                ]
                
                # Add semantic enrichment
                if row['type'] == 'mariage' or 'wedding' in str(row).lower():
                    text_parts.append('wedding photography outdoor event')
                elif row['type'] == 'interview':
                    text_parts.append('professional interview setup indoor studio')
                elif row['type'] == 'documentaire':
                    text_parts.append('documentary filming natural lighting')
                
                full_text = ' '.join(text_parts)
                processed_text = self._enhanced_preprocess_text(full_text)
                config_texts.append(processed_text)
            
            # Compute embeddings in batches for efficiency
            batch_size = 32
            embeddings = []
            
            for i in range(0, len(config_texts), batch_size):
                batch = config_texts[i:i + batch_size]
                batch_embeddings = self.embedder.encode(batch, 
                                                      convert_to_tensor=False,
                                                      show_progress_bar=False)
                embeddings.extend(batch_embeddings)
            
            self.config_embeddings = np.array(embeddings)
            logger.info("  Enhanced configuration embeddings pre-computed")
            
        except Exception as e:
            logger.error(f"  Error pre-computing embeddings: {e}")
            raise
    
    def _setup_advanced_features(self):
        """Setup advanced features like PCA for dimensionality reduction"""
        try:
            # Apply PCA to reduce embedding dimensions and improve performance
            if self.config_embeddings is not None:
                self.pca = PCA(n_components=min(100, self.config_embeddings.shape[1]))
                self.config_embeddings_pca = self.pca.fit_transform(self.config_embeddings)
                logger.info("  PCA dimensionality reduction applied")
            
        except Exception as e:
            logger.warning(f"   Advanced features setup failed: {e}")
    
    def _enhanced_preprocess_text(self, text):
        """Enhanced text preprocessing with better French handling"""
        if not isinstance(text, str) or not text.strip():
            return ""

        text = text.lower().strip()
        
        # Remove special characters but keep accents and hyphens
        text = re.sub(r'[^\w\s\-Ã Ã¢Ã¤Ã©Ã¨ÃªÃ«Ã¯Ã®Ã´Ã¶Ã¹Ã»Ã¼Ã¿Ã§]', ' ', text)
        
        # Apply enhanced synonym replacement
        for syn, std in self.SYNONYMS.items():
            text = re.sub(r'\b' + re.escape(syn) + r'\b', std, text)
        
        # Normalize spaces
        text = re.sub(r'\s+', ' ', text).strip()
        
        # French-specific enhancements
        if self.nlp:
            try:
                doc = self.nlp(text)
                # Extract lemmas for better matching
                lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
                if lemmas:
                    text = text + ' ' + ' '.join(lemmas)
            except:
                pass
        
        return text
    
    def _extract_enhanced_features(self, query):
        """Enhanced feature extraction with better accuracy"""
        processed_query = self._enhanced_preprocess_text(query)
        words = set(processed_query.split())
        
        # Define enhanced canonical values
        BUDGET_VALUES = {'low', 'medium', 'high'}
        LIEU_VALUES = {'intÃ©rieur', 'extÃ©rieur', 'studio'}
        TYPE_VALUES = set(self.configs['type'].unique())
        
        # Enhanced extraction with context understanding
        features = {
            'budget': None,
            'lieu': None,
            'type': None,
            'specificity_score': 0
        }
        
        # Budget detection with context
        budget_patterns = {
            'low': ['low', 'faible', 'petit', 'Ã©conomique', 'pas cher', 'serrÃ©'],
            'medium': ['medium', 'moyen', 'normal', 'standard', 'correct'],
            'high': ['high', 'Ã©levÃ©', 'grand', 'cher', 'premium', 'luxe', 'haut']
        }
        
        for budget, patterns in budget_patterns.items():
            if any(pattern in processed_query for pattern in patterns):
                features['budget'] = budget
                features['specificity_score'] += 1
                break
        
        # Location detection
        for lieu in LIEU_VALUES:
            if lieu in words or any(syn in words for syn, std in self.SYNONYMS.items() if std == lieu):
                features['lieu'] = lieu
                features['specificity_score'] += 1
                break
        
        # Type detection with semantic understanding
        for ptype in TYPE_VALUES:
            if ptype in words:
                features['type'] = ptype
                features['specificity_score'] += 2  # Type is more important
                break
        
        # Context-based type inference
        if not features['type']:
            if any(word in processed_query for word in ['mariage', 'wedding', 'photo']):
                features['type'] = 'pub'  # Wedding photography often falls under commercial
                features['specificity_score'] += 1
            elif any(word in processed_query for word in ['entretien', 'reportage']):
                features['type'] = 'interview'
                features['specificity_score'] += 1
        
        return features
    
    def _calculate_enhanced_scores(self, query):
        """Enhanced scoring algorithm matching your Colab performance"""
        try:
            processed_query = self._enhanced_preprocess_text(query)
            
            if not processed_query:
                return np.zeros(len(self.configs))
            
            # 1. Semantic similarity with enhanced embeddings
            query_embedding = self.embedder.encode([processed_query])
            
            # Use PCA embeddings if available for better performance
            if hasattr(self, 'config_embeddings_pca'):
                query_pca = self.pca.transform(query_embedding)
                semantic_scores = cosine_similarity(query_pca, self.config_embeddings_pca)[0]
            else:
                semantic_scores = cosine_similarity(query_embedding, self.config_embeddings)[0]
            
            # 2. Enhanced keyword matching with TF-IDF like scoring
            query_words = set(processed_query.split())
            keyword_scores = []
            
            for _, row in self.configs.iterrows():
                config_text = self._enhanced_preprocess_text(f"{row['type']} {row['budget']} {row['lieu']}")
                config_words = set(config_text.split())
                
                # Enhanced Jaccard with term frequency weighting
                intersection = len(query_words.intersection(config_words))
                union = len(query_words.union(config_words))
                
                # Bonus for exact term matches
                exact_matches = sum(1 for word in query_words if word in config_words)
                jaccard = intersection / union if union > 0 else 0
                
                # Weighted score
                keyword_score = jaccard + (exact_matches * 0.1)
                keyword_scores.append(keyword_score)
            
            keyword_scores = np.array(keyword_scores)
            
            # 3. Feature-based boosting (enhanced)
            extracted = self._extract_enhanced_features(processed_query)
            boosts = np.ones(len(self.configs))
            
            # Dynamic boosting based on feature specificity
            boost_strength = 0.3 + (extracted['specificity_score'] * 0.1)
            
            if extracted['type']:
                type_match = (self.configs['type'] == extracted['type']).astype(float)
                boosts += boost_strength * type_match
            
            if extracted['budget']:
                budget_match = (self.configs['budget'] == extracted['budget']).astype(float)
                boosts += boost_strength * budget_match
            
            if extracted['lieu']:
                lieu_match = (self.configs['lieu'] == extracted['lieu']).astype(float)
                boosts += boost_strength * lieu_match
            
            # 4. Equipment quality scoring
            quality_scores = self.configs['complexity_score'].values / self.configs['complexity_score'].max()
            
            # 5. Price appropriateness scoring
            if extracted['budget']:
                budget_tier = {'low': 1, 'medium': 2, 'high': 3}[extracted['budget']]
                price_scores = 1 - abs(self.configs['budget_tier'].values - budget_tier) / 3
            else:
                price_scores = np.ones(len(self.configs))
            
            # 6. Combined scoring with weights optimized from your Colab version
            base_scores = (semantic_scores * 0.4) + (keyword_scores * 0.3)
            final_scores = base_scores * boosts * (1 + quality_scores * 0.2) * (0.8 + price_scores * 0.2)
            
            # Normalize scores
            if final_scores.max() > 0:
                final_scores = final_scores / final_scores.max()
            
            return final_scores
            
        except Exception as e:
            logger.error(f"  Error calculating enhanced scores: {e}")
            return np.random.uniform(0.1, 0.3, len(self.configs))
    
    def get_recommendations(self, user_query, jours=1):
        """Get enhanced equipment recommendations matching Colab quality"""
        try:
            if not self.is_initialized:
                raise Exception("Enhanced model not initialized")
            
            logger.info(f"   Processing enhanced query: '{user_query}' for {jours} day(s)")
            
            if len(user_query.strip()) < 3:
                return {
                    'success': False,
                    'message': 'Query too short. Please be more specific.',
                    'recommendations': []
                }
            
            # Calculate enhanced scores
            similarities = self._calculate_enhanced_scores(user_query)
            top_indices = similarities.argsort()[::-1]
            
            # Build diverse, high-quality results
            results = []
            seen_combinations = set()
            quality_threshold = 0.15  # Lower threshold for better recall
            
            for idx in top_indices:
                if len(results) >= 5:
                    break
                
                row = self.configs.iloc[idx]
                
                # Ensure variety while maintaining quality
                combo_key = (row['type'], row['budget'], row['lieu'])
                
                # Allow some similarity but avoid exact duplicates
                similar_count = sum(1 for seen in seen_combinations 
                                  if sum(a == b for a, b in zip(combo_key, seen)) >= 2)
                
                if similar_count >= 2:  # Max 2 similar configurations
                    continue
                
                seen_combinations.add(combo_key)
                
                # Quality threshold check
                if similarities[idx] < quality_threshold:
                    continue
                
                # Create enhanced result
                result = {
                    'type': row['type'],
                    'budget': row['budget'],
                    'lieu': row['lieu'],
                    'camera': row['camera'],
                    'objectif': row['objectif'],
                    'lumieres': row['lumieres'],
                    'prix_jour': int(row['prix_jour']),
                    'prix_total': int(row['prix_jour'] * jours),
                    'duree': jours,
                    'score': round(similarities[idx], 3),
                    'confidence': self._calculate_confidence(similarities[idx]),
                    'complexity_score': row['complexity_score'],
                    'quality_rating': min(5, round(similarities[idx] * 5 + 1))
                }
                results.append(result)
            
            success = len(results) > 0
            message = f"Found {len(results)} high-quality recommendations" if success else "No close matches found"
            
            return {
                'success': success,
                'message': message,
                'query': user_query,
                'duration_days': jours,
                'recommendations': results,
                'extracted_features': self._extract_enhanced_features(user_query),
                'model_confidence': np.mean([r['score'] for r in results]) if results else 0
            }
            
        except Exception as e:
            logger.error(f"  Error getting enhanced recommendations: {e}")
            return {
                'success': False,
                'message': str(e),
                'recommendations': []
            }
    
    def _calculate_confidence(self, score):
        """Calculate confidence level based on score"""
        if score > 0.8:
            return 'excellent'
        elif score > 0.6:
            return 'very_good'
        elif score > 0.4:
            return 'good'
        elif score > 0.2:
            return 'fair'
        else:
            return 'low'
    
    def validate_query(self, query):
        """Enhanced query validation"""
        if not query or len(query.strip()) < 3:
            return False
            
        query_lower = query.lower()
        
        # Enhanced validation with more keywords
        has_valid_keyword = any(mot in query_lower for mot in self.MOTS_CLES_VALIDES)
        
        # Check for equipment-related context
        equipment_context = any(word in query_lower for word in [
            'Ã©quipement', 'matÃ©riel', 'camera', 'camÃ©ra', 'film', 'photo',
            'tournage', 'projet', 'location', 'besoin'
        ])
        
        return has_valid_keyword or equipment_context
    
    def get_query_suggestions(self):
        """Enhanced query suggestions"""
        return [
            "court mÃ©trage en extÃ©rieur avec budget moyen",
            "interview professionnelle en studio avec budget Ã©levÃ©",
            "clip musical dehors budget faible",
            "documentaire nature budget Ã©conomique", 
            "publicitÃ© luxe en studio",
            "mariage en extÃ©rieur avec grand budget",
            "photographe portrait en intÃ©rieur",
            "Ã©vÃ©nement live streaming professionnel"
        ]
    
    def get_equipment_stats(self):
        """Get enhanced equipment statistics"""
        try:
            if not self.is_initialized:
                return {}
            
            stats = {
                'total_configurations': len(self.configs),
                'categories': dict(self.configs['type'].value_counts()),
                'budget_distribution': dict(self.configs['budget'].value_counts()),
                'location_distribution': dict(self.configs['lieu'].value_counts()),
                'average_price': round(self.configs['prix_jour'].mean(), 2),
                'price_range': {
                    'min': int(self.configs['prix_jour'].min()),
                    'max': int(self.configs['prix_jour'].max())
                },
                'complexity_stats': {
                    'average_complexity': round(self.configs['complexity_score'].mean(), 2),
                    'max_complexity': int(self.configs['complexity_score'].max())
                },
                'equipment_brands': {
                    'cameras': list(self.configs['camera'].value_counts().head(5).index),
                    'lenses': list(self.configs['objectif'].value_counts().head(5).index),
                    'lights': list(self.configs['lumieres'].value_counts().head(5).index)
                }
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"  Error getting enhanced stats: {e}")
            return {}
    
    def get_model_info(self):
        """Get enhanced model information"""
        return {
            'is_initialized': self.is_initialized,
            'embedder_model': 'paraphrase-multilingual-MiniLM-L12-v2',
            'nlp_model': 'fr_core_news_sm' if self.nlp else 'basic_processing',
            'data_records': len(self.configs) if self.configs is not None else 0,
            'features': [
                'enhanced_semantic_similarity', 
                'advanced_keyword_matching', 
                'feature_boosting',
                'quality_scoring',
                'price_appropriateness',
                'pca_optimization'
            ],
            'accuracy_optimized': True,
            'colab_equivalent': True,
            'supported_languages': ['French', 'English'],
            'version': '2.0_enhanced'
        }